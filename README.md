# ğŸ“„ DocuAI â€” AI-Powered Document Management System

**DocuAI** is a self-hosted, AI-powered document management system that automatically organizes, classifies, and makes your documents searchable using local LLMs via Ollama. Think of it as Paperless-ngx meets AI â€” with OCR, semantic search, automatic tagging, and a modern web interface.

> ğŸ”’ **100% local & private** â€” your documents never leave your server. All AI processing runs on your own hardware via Ollama.

---

## âœ¨ Features

- **ğŸ“¥ Auto-Ingest** â€” Drop files into a watched folder and they're automatically processed
- **ğŸ” OCR** â€” Extract text from scanned PDFs and images (Tesseract, multi-language)
- **ğŸ¤– AI Classification** â€” Automatic categorization, tagging, and title generation via Ollama LLMs
- **ğŸ‘ï¸ Vision AI** â€” Analyze document images with vision models (minicpm-v, llava, etc.)
- **ğŸ” Semantic Search** â€” Find documents by meaning, not just keywords (pgvector embeddings)
- **ğŸ“Š Smart Dashboard** â€” Overview of recent documents, processing status, and statistics
- **ğŸ·ï¸ Auto-Tagging** â€” AI-generated tags, correspondents, and document types
- **ğŸ“± Responsive UI** â€” Modern React frontend that works on desktop and mobile
- **ğŸŒ Multi-Language OCR** â€” German, English, Arabic, and more out of the box
- **ğŸ“¤ REST API** â€” Full API for integration with other tools
- **ğŸ³ Docker-Based** â€” Easy deployment with Docker Compose or Portainer
- **ğŸ”„ Background Workers** â€” Celery-based async processing pipeline

---

## ğŸ“¸ Screenshots

> *Screenshots will be added after the first release.*

| Dashboard | Document View | Search |
|-----------|---------------|--------|
| ![Dashboard](docs/screenshots/dashboard.png) | ![Document](docs/screenshots/document.png) | ![Search](docs/screenshots/search.png) |

---

## ğŸš€ Quick Start

### One-Line Install (Ubuntu/Debian/Proxmox LXC)

```bash
# Clone or download the project
git clone https://github.com/fahmykhattab/docuai.git
cd docuai

# Run the installer as root
sudo bash install.sh
```

The installer will:
1. Install Docker and Docker Compose (if not present)
2. Copy files to `/opt/docuai/`
3. Ask for your Ollama URL and preferences
4. Generate a secure `.env` configuration
5. Build and start all containers
6. Show you the access URL when ready

---

## ğŸ› ï¸ Manual Docker Compose Setup

If you prefer manual setup:

### 1. Clone and Configure

```bash
git clone https://github.com/fahmykhattab/docuai.git /opt/docuai
cd /opt/docuai
```

### 2. Create `.env` File

```bash
cp .env.example .env
# Edit with your settings
nano .env
```

Minimal `.env`:

```env
POSTGRES_PASSWORD=your_secure_password_here
SECRET_KEY=your_secret_key_here
OLLAMA_URL=http://192.168.178.37:11434
OLLAMA_MODEL=qwen3:8b
OLLAMA_VISION_MODEL=minicpm-v
```

### 3. Create Data Directories

```bash
mkdir -p data/{consume,media,thumbnails,export,trash}
chmod -R 777 data
```

### 4. Build and Start

```bash
docker compose build
docker compose up -d
```

### 5. Verify

```bash
# Check all services are running
docker compose ps

# Check backend health
curl http://localhost:3000/api/health

# View logs
docker compose logs -f
```

---

## ğŸ–¥ï¸ Portainer Deployment

DocuAI includes a Portainer-optimized compose file for easy stack deployment.

### Steps

1. Open Portainer â†’ **Stacks** â†’ **Add Stack**
2. Name the stack: `docuai`
3. Choose **Upload** and select `docker-compose.portainer.yml`, or paste its contents
4. Add **Environment Variables** in the Portainer UI:

   | Variable | Required | Default | Description |
   |----------|----------|---------|-------------|
   | `POSTGRES_PASSWORD` | âœ… | â€” | Database password |
   | `SECRET_KEY` | âœ… | â€” | Application secret key |
   | `OLLAMA_URL` | âœ… | `http://host.docker.internal:11434` | Ollama API endpoint |
   | `OLLAMA_MODEL` | âŒ | `qwen3:8b` | LLM model name |
   | `OLLAMA_VISION_MODEL` | âŒ | `minicpm-v` | Vision model name |
   | `DOCUAI_REGISTRY` | âŒ | `docuai` | Docker registry prefix |
   | `DOCUAI_VERSION` | âŒ | `latest` | Image version tag |
   | `DOCUAI_DATA_PATH` | âŒ | `/opt/docuai/data` | Host path for document storage |
   | `UI_PORT` | âŒ | `3000` | Web UI port |

5. Click **Deploy the stack**

### Pre-Building Images for Portainer

If you don't want Portainer to build images, pre-build them:

```bash
cd /opt/docuai

# Build and tag
docker compose build
docker tag docuai-backend:latest docuai/backend:latest
docker tag docuai-frontend:latest docuai/frontend:latest

# Or push to a private registry
docker tag docuai-backend:latest registry.local:5000/docuai/backend:latest
docker push registry.local:5000/docuai/backend:latest
```

### Traefik Integration

The Portainer compose includes Traefik labels. To enable:

1. Set `DOCUAI_DOMAIN=docuai.yourdomain.com` in environment variables
2. Ensure Traefik is running on the same Docker network or adjust the network config

---

## âš™ï¸ Configuration Reference

All configuration is done via environment variables in the `.env` file.

### Database

| Variable | Default | Description |
|----------|---------|-------------|
| `POSTGRES_USER` | `docuai` | PostgreSQL username |
| `POSTGRES_PASSWORD` | â€” | PostgreSQL password (**required**) |
| `POSTGRES_DB` | `docuai` | PostgreSQL database name |

### Redis

| Variable | Default | Description |
|----------|---------|-------------|
| `REDIS_URL` | `redis://redis:6379/0` | Redis connection URL |

### Ollama AI

| Variable | Default | Description |
|----------|---------|-------------|
| `OLLAMA_URL` | `http://host.docker.internal:11434` | Ollama API base URL |
| `OLLAMA_MODEL` | `qwen3:8b` | LLM model for text processing |
| `OLLAMA_VISION_MODEL` | `minicpm-v` | Vision model for image analysis |

### Application

| Variable | Default | Description |
|----------|---------|-------------|
| `SECRET_KEY` | â€” | Application secret for JWT/sessions (**required**) |
| `MAX_UPLOAD_SIZE_MB` | `50` | Maximum file upload size in megabytes |
| `OCR_LANGUAGE` | `deu+eng+ara` | Tesseract OCR languages (+ separated) |
| `UI_PORT` | `3000` | Web UI port (used by install.sh) |

### Portainer-Specific

| Variable | Default | Description |
|----------|---------|-------------|
| `DOCUAI_REGISTRY` | `docuai` | Docker image registry prefix |
| `DOCUAI_VERSION` | `latest` | Docker image version tag |
| `DOCUAI_DATA_PATH` | `/opt/docuai/data` | Host path for the data volume bind mount |
| `DOCUAI_DOMAIN` | `docuai.local` | Domain for Traefik reverse proxy labels |

### Derived URLs (auto-constructed in compose)

| Internal Variable | Value |
|-------------------|-------|
| `DATABASE_URL` | `postgresql+asyncpg://<user>:<pass>@postgres:5432/<db>` |
| `SYNC_DATABASE_URL` | `postgresql+psycopg2://<user>:<pass>@postgres:5432/<db>` |

---

## ğŸ“¡ API Documentation Summary

The backend exposes a RESTful API at `/api`.

### Health

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/health` | GET | Health check â€” returns `{"status": "ok"}` |

### Documents

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/documents` | GET | List documents (paginated, filterable) |
| `/api/documents` | POST | Upload a new document |
| `/api/documents/{id}` | GET | Get document details |
| `/api/documents/{id}` | PUT | Update document metadata |
| `/api/documents/{id}` | DELETE | Delete a document |
| `/api/documents/{id}/download` | GET | Download original file |
| `/api/documents/{id}/thumbnail` | GET | Get document thumbnail |
| `/api/documents/{id}/reprocess` | POST | Re-run AI processing |

### Search

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/search` | GET | Full-text and semantic search |
| `/api/search/similar/{id}` | GET | Find similar documents |

### Tags & Categories

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/tags` | GET | List all tags |
| `/api/tags` | POST | Create a tag |
| `/api/correspondents` | GET | List correspondents |
| `/api/document-types` | GET | List document types |

### Processing

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/tasks` | GET | List background tasks |
| `/api/tasks/{id}` | GET | Get task status |

### Authentication

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/auth/login` | POST | Login and get JWT token |
| `/api/auth/register` | POST | Register new user (if enabled) |
| `/api/auth/me` | GET | Get current user profile |

> Full OpenAPI/Swagger documentation is available at `/api/docs` when the backend is running.

---

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Browser                          â”‚
â”‚                    (React Frontend)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP :3000
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Nginx (Frontend)                       â”‚
â”‚              Serves SPA + proxies /api                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP :8000
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FastAPI Backend                           â”‚
â”‚          REST API â€¢ Auth â€¢ Document CRUD                 â”‚
â”‚          OCR â€¢ AI Classification â€¢ Search                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚             â”‚
   â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
   â”‚ Postgres â”‚   â”‚   Redis   â”‚  â”‚ Ollama â”‚
   â”‚ pgvector â”‚   â”‚  (Celery  â”‚  â”‚ (LLM)  â”‚
   â”‚          â”‚   â”‚   broker) â”‚  â”‚        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                  â”‚  Celery   â”‚
                  â”‚  Worker   â”‚
                  â”‚ (async    â”‚
                  â”‚  tasks)   â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   File Watcher                           â”‚
â”‚        Monitors data/consume/ for new files              â”‚
â”‚        Triggers ingestion pipeline automatically         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services

| Service | Role | Port |
|---------|------|------|
| **frontend** | React SPA served by Nginx, proxies API calls | 3000 (â†’ 80 internal) |
| **backend** | FastAPI application server | 8000 (internal) |
| **worker** | Celery worker for async document processing | â€” |
| **watcher** | File system watcher for auto-ingest | â€” |
| **postgres** | PostgreSQL 16 with pgvector extension | 5432 (internal) |
| **redis** | Message broker and cache | 6379 (internal) |
| **Ollama** | LLM inference server (external) | 11434 (external) |

### Processing Pipeline

1. **Ingest** â€” File uploaded via API or dropped into `data/consume/`
2. **Store** â€” Original file saved to `data/media/`, metadata created in PostgreSQL
3. **OCR** â€” Tesseract extracts text from PDFs/images (Celery task)
4. **Embed** â€” Text converted to vector embeddings and stored in pgvector
5. **Classify** â€” Ollama LLM analyzes content and assigns:
   - Title
   - Document type
   - Correspondent
   - Tags
   - Date
   - Summary
6. **Thumbnail** â€” Preview image generated and stored in `data/thumbnails/`
7. **Index** â€” Full-text search index updated

---

## ğŸ“¥ Folder Watcher Usage

The watcher service monitors the `data/consume/` directory for new files.

### How It Works

1. Place any supported file into `data/consume/`
2. The watcher detects the new file within seconds
3. The file is moved to `data/media/` and processing begins
4. AI classification, OCR, and embedding run automatically
5. The document appears in the web UI once processed

### Supported File Types

- **PDF** â€” `.pdf` (native text extraction + OCR for scanned pages)
- **Images** â€” `.jpg`, `.jpeg`, `.png`, `.tiff`, `.webp`
- **Documents** â€” `.docx`, `.doc`, `.odt`, `.txt`, `.rtf`
- **Spreadsheets** â€” `.xlsx`, `.xls`, `.csv`

### Batch Import

```bash
# Copy a folder of documents for batch processing
cp ~/Documents/taxes/*.pdf /opt/docuai/data/consume/

# Or use rsync for large batches
rsync -av ~/Documents/archive/ /opt/docuai/data/consume/
```

### Network Share

You can mount a network share directly to the consume folder:

```bash
# SMB/CIFS
mount -t cifs //nas/scans /opt/docuai/data/consume -o user=scanner,password=xxx

# NFS
mount -t nfs nas:/exports/scans /opt/docuai/data/consume
```

---

## ğŸ”§ Troubleshooting

### Services won't start

```bash
# Check which services are running
cd /opt/docuai && docker compose ps

# View logs for all services
docker compose logs

# View logs for a specific service
docker compose logs backend
docker compose logs worker
```

### Backend health check fails

```bash
# Check if backend is actually running
docker compose logs backend --tail 50

# Common causes:
# - PostgreSQL not ready yet (wait longer)
# - Invalid DATABASE_URL in .env
# - Missing POSTGRES_PASSWORD
```

### Ollama connection issues

```bash
# Test connectivity from the backend container
docker compose exec backend curl http://your-ollama-host:11434/api/tags

# If using host.docker.internal (default):
# - On Linux, add to docker-compose.yml backend service:
#     extra_hosts:
#       - "host.docker.internal:host-gateway"
# - Or set OLLAMA_URL to the actual IP address

# Verify Ollama has the required models
curl http://your-ollama-host:11434/api/tags
# Should list qwen3:8b and minicpm-v
```

### OCR not working

```bash
# Check if Tesseract languages are installed in the container
docker compose exec backend tesseract --list-langs

# If a language is missing, it needs to be added to the backend Dockerfile
```

### Documents stuck in processing

```bash
# Check worker status
docker compose logs worker --tail 50

# Restart the worker
docker compose restart worker

# Check Redis connectivity
docker compose exec redis redis-cli ping
```

### Permission issues with data directory

```bash
# Reset permissions
chmod -R 777 /opt/docuai/data

# Or set proper ownership (UID 1000 is typical for container user)
chown -R 1000:1000 /opt/docuai/data
```

### Database issues

```bash
# Connect to PostgreSQL
docker compose exec postgres psql -U docuai -d docuai

# Check pgvector extension
docker compose exec postgres psql -U docuai -d docuai -c "SELECT extname FROM pg_extension;"

# Reset database (WARNING: destroys all data)
docker compose down -v
docker compose up -d
```

### Out of disk space

```bash
# Check Docker disk usage
docker system df

# Clean up unused images
docker image prune -a

# Check data directory size
du -sh /opt/docuai/data/*
```

### Container can't resolve host.docker.internal (Linux)

Add this to the backend, worker, and watcher services in `docker-compose.yml`:

```yaml
    extra_hosts:
      - "host.docker.internal:host-gateway"
```

### Updating DocuAI

```bash
cd /opt/docuai

# Pull latest code
git pull

# Rebuild and restart
docker compose build
docker compose up -d
```

---

## ğŸ“‚ Directory Structure

```
docuai/
â”œâ”€â”€ backend/                 # FastAPI backend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/             # API route handlers
â”‚   â”‚   â”œâ”€â”€ models/          # SQLAlchemy database models
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic (OCR, AI, watcher)
â”‚   â”‚   â”œâ”€â”€ core/            # Config, security, database setup
â”‚   â”‚   â””â”€â”€ schemas/         # Pydantic request/response schemas
â”‚   â”œâ”€â”€ celery_app.py        # Celery worker configuration
â”‚   â”œâ”€â”€ Dockerfile           # Backend Docker image
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ frontend/                # React frontend application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React UI components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page-level components
â”‚   â”‚   â”œâ”€â”€ services/        # API client
â”‚   â”‚   â””â”€â”€ stores/          # State management
â”‚   â”œâ”€â”€ Dockerfile           # Frontend Docker image (Nginx)
â”‚   â””â”€â”€ package.json         # Node.js dependencies
â”œâ”€â”€ data/                    # Document storage (bind mount)
â”‚   â”œâ”€â”€ consume/             # Drop files here for auto-ingest
â”‚   â”œâ”€â”€ media/               # Stored original documents
â”‚   â”œâ”€â”€ thumbnails/          # Generated preview images
â”‚   â”œâ”€â”€ export/              # Exported documents
â”‚   â””â”€â”€ trash/               # Soft-deleted documents
â”œâ”€â”€ docker-compose.yml       # Main Docker Compose file
â”œâ”€â”€ docker-compose.portainer.yml  # Portainer-optimized compose
â”œâ”€â”€ install.sh               # One-click installer script
â”œâ”€â”€ .env                     # Configuration (generated, gitignored)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .dockerignore
â””â”€â”€ README.md                # This file
```

---

## ğŸ“„ License

This project is licensed under the **MIT License**.

```
MIT License

Copyright (c) 2025 DocuAI

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
